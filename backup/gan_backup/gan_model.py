import os

import gan.gan_interface as interface
import tensorflow as tf

os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'


class GAN:

    def __init__(self, _MAXLENGTH, interface):
        """
        Defines the structure and calculation model of a GAN
        """
        # Parameter
        self._MAXLENGTH = _MAXLENGTH
        self.itf = interface
        self.generator_input_length = 5

        # Generator model
        self.G_X = tf.placeholder(tf.float32, shape=[None, self.generator_input_length])
        G_W1 = tf.Variable(tf.random_uniform([5, 16], -0.037, 0.037))
        G_B1 = tf.Variable(tf.zeros([16]))
        G_W2 = tf.Variable(tf.random_uniform([16, 50], -0.088, 0.088))
        G_B2 = tf.Variable(tf.zeros([50]))
        G_model_part1 = tf.nn.relu(tf.matmul(self.G_X, G_W1) + G_B1)
        self.G_model = tf.sigmoid(tf.matmul(G_model_part1, G_W2) + G_B2)

        # Discriminator model
        self.D_X = tf.placeholder(tf.float32, shape=[None, 50])
        D_W1 = tf.Variable(tf.random_uniform([50, 16], -0.18, 0.18))
        D_B1 = tf.Variable(tf.zeros([16]))
        D_W2 = tf.Variable(tf.random_uniform([16, 1], -0.088, 0.088))
        D_B2 = tf.Variable(tf.zeros(1))
        D_model_part1_X = tf.nn.relu(tf.matmul(self.D_X, D_W1) + D_B1)
        D_model_X = tf.sigmoid(tf.matmul(D_model_part1_X, D_W2) + D_B2)
        D_model_part1_G = tf.nn.relu(tf.matmul(self.G_model, D_W1) + D_B1)
        D_model_G = tf.sigmoid(tf.matmul(D_model_part1_G, D_W2) + D_B2)

        # Define loss functions
        D_loss = -tf.reduce_mean(tf.log(D_model_X) + tf.log(1. - D_model_G))
        G_loss = -tf.reduce_mean(tf.log(D_model_G))

        # Define train functions
        self.D_train = tf.train.AdamOptimizer().minimize(D_loss, var_list=[D_W1, D_W2])
        self.G_train = tf.train.AdamOptimizer().minimize(G_loss, var_list=[G_W1, G_W2])

        # Define logging data for discriminator
        tf.summary.scalar("discriminator loss", D_loss)
        self.summary_op = tf.summary.merge_all()

        # Define logging data for generator
        #tf.summary.scalar("generator loss", G_loss)
        #self.summary_op = tf.summary.merge_all()

        # Initialize Session
        self.sess = tf.Session()
        self.sess.run(tf.global_variables_initializer())


    def train(self, data):
        """
        Trains the model with given dataset (list of samples)
        """

        # Get random inputs for discriminator
        random_inputs = []
        for i in range(len(data)):
            random_inputs.append(self.itf.getRandomInput(self.generator_input_length))

        # Train discriminator
        summary, placeholder = self.sess.run([self.summary_op, self.D_train], feed_dict={self.D_X: data, self.G_X: random_inputs})

        # Get random inputs for generator
        random_inputs = []
        for i in range(len(data)):
            random_inputs.append(self.itf.getRandomInput(self.generator_input_length))

        # train generator
        self.sess.run(self.G_train, feed_dict={self.G_X: random_inputs})
        return summary


    def getSample(self):
        """
        Returns a sample generated by the Generator Net of the GAN
        """
        return self.sess.run(self.G_model, feed_dict={self.G_X: [self.itf.getRandomInput(self.generator_input_length)]})


    def evaluate(self):
        """
        Calculates the accuracy of the model and returns it
        """
        pos = 0
        for i in range(10000):
            s = self.itf.calcstring(self.getSample()[0])
            if self.itf.match(s):
                pos += 1
        return (pos/10000)